{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Causal Inference with Factorial Design\n",
    "\n",
    "### **Objective:** Provide accurate and scalable model to solve the causal clustering problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn import preprocessing\n",
    "from itertools import combinations\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up FactorialModel class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FactorialModel(object):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n,\n",
    "        p_t=0.5,\n",
    "        k=2,\n",
    "        degree=2,\n",
    "        sigma=0.1,\n",
    "        sparsity=0.5,\n",
    "        beta_seed=42,\n",
    "    ) -> None:\n",
    "        self.n = n\n",
    "        self.p_t = p_t\n",
    "        self.k = k\n",
    "        self.degree = degree\n",
    "        self.sigma = sigma\n",
    "        self.sparsity = sparsity\n",
    "        self.beta_seed = beta_seed\n",
    "        # initialize beta random number generator\n",
    "        self.rng_beta = np.random.default_rng(self.beta_seed)\n",
    "        # initialize interaction expansion transformation\n",
    "        self.xfm = preprocessing.PolynomialFeatures(\n",
    "            degree=self.degree, interaction_only=True, include_bias=True\n",
    "        )\n",
    "        _ = self.xfm.fit_transform(np.zeros((1, self.k), dtype=\"float32\"))\n",
    "        # sample ground truth betas\n",
    "        self.beta = self.rng_beta.normal(0, 1, self.xfm.n_output_features_).astype(\n",
    "            \"float32\"\n",
    "        )\n",
    "        zero_indices = self.rng_beta.choice(\n",
    "            self.xfm.n_output_features_,\n",
    "            size=int(self.xfm.n_output_features_ * self.sparsity),\n",
    "            replace=False,\n",
    "        )\n",
    "        self.beta[zero_indices] = 0.0\n",
    "\n",
    "    def sample(self, seed=None):\n",
    "        self.rng = np.random.default_rng(seed)\n",
    "        # sample treatment array\n",
    "        t = self.rng.binomial(1, self.p_t, (self.n, self.k)).astype(\"float32\")\n",
    "        # expand treatment array\n",
    "        T = self.xfm.fit_transform(t)\n",
    "        # build response surface\n",
    "        self.mu = T @ self.beta\n",
    "        # sample outcome\n",
    "        self.eps = self.rng.normal(0, self.sigma, size=self.n)\n",
    "        y = self.mu + self.eps\n",
    "        return t, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize model parameters\n",
    "\n",
    "$\\beta_{1:k} \\sim \\mathcal{N}(0, 1)$, with uniform random sparsity imposed on all parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000\n",
    "k = 3\n",
    "degree = 3\n",
    "sigma = 0.1\n",
    "sparsity = 0.5\n",
    "\n",
    "fm = FactorialModel(\n",
    "    n=n,\n",
    "    k=k,\n",
    "    degree=degree,\n",
    "    sigma=sigma,\n",
    "    sparsity=sparsity,\n",
    "    beta_seed=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For `degree=3` and `interaction_only=True`, the parameters appear in the following order: [bias, $\\beta_{t_1}$, $\\beta_{t_2}$, $\\beta_{t_3}$, $\\beta_{t_1, t_2}$, $\\beta_{t_1, t_3}$, $\\beta_{t_2, t_3}$, $\\beta_{t_1, t_2, t_3}$]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.        -1.0399841  0.         0.        -1.9510351  0.\n",
      "  0.1278404 -0.3162426]\n"
     ]
    }
   ],
   "source": [
    "print(fm.beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a sample dataset\n",
    "\n",
    "**Treatment matrix:** $t_{n,k} \\sim Bern(p_t=0.5)$; $T = t_{\\text{expanded}}$\n",
    "\n",
    "**Outcomes (for k=3):** $y_i = \\beta_{i,0} + \\beta_{i,1} t_{i,1} + \\beta_{i,2} t_{i,2} + \\beta_{i,3} t_{i,3} + \\beta_{i,12} t_{i,12} + \\beta_{i,13} t_{i,13} + \\beta_{i,23} t_{i,23} + \\beta_{i,123} t_{i,123} + \\epsilon$ where $\\epsilon \\sim \\mathcal{N}(0, \\sigma)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 3) (1000,)\n"
     ]
    }
   ],
   "source": [
    "t, y = fm.sample(seed=0)\n",
    "print(t.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit OLS model with sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 8)\n"
     ]
    }
   ],
   "source": [
    "T = preprocessing.PolynomialFeatures(\n",
    "    degree=degree, interaction_only=True, include_bias=True,\n",
    ").fit_transform(t)\n",
    "print(T.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.993\n",
      "Model:                            OLS   Adj. R-squared:                  0.993\n",
      "Method:                 Least Squares   F-statistic:                 2.093e+04\n",
      "Date:                Tue, 27 Feb 2024   Prob (F-statistic):               0.00\n",
      "Time:                        11:00:44   Log-Likelihood:                 881.00\n",
      "No. Observations:                1000   AIC:                            -1746.\n",
      "Df Residuals:                     992   BIC:                            -1707.\n",
      "Df Model:                           7                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0085      0.009      0.964      0.335      -0.009       0.026\n",
      "x1            -1.0455      0.013    -81.708      0.000      -1.071      -1.020\n",
      "x2            -0.0041      0.012     -0.327      0.744      -0.029       0.020\n",
      "x3             0.0047      0.013      0.359      0.719      -0.021       0.030\n",
      "x4            -1.9355      0.018   -107.599      0.000      -1.971      -1.900\n",
      "x5            -0.0082      0.018     -0.456      0.649      -0.043       0.027\n",
      "x6             0.1175      0.018      6.602      0.000       0.083       0.152\n",
      "x7            -0.3124      0.026    -12.170      0.000      -0.363      -0.262\n",
      "==============================================================================\n",
      "Omnibus:                        1.542   Durbin-Watson:                   1.996\n",
      "Prob(Omnibus):                  0.463   Jarque-Bera (JB):                1.618\n",
      "Skew:                           0.086   Prob(JB):                        0.445\n",
      "Kurtosis:                       2.903   Cond. No.                         17.5\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "m = sm.OLS(y, T)\n",
    "results = m.fit()\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average Marginal Interaction Effect (AMIE)\n",
    "\n",
    "[Egami & Imai, 2018](https://www.tandfonline.com/doi/10.1080/01621459.2018.1476246)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AMIE can be expressed as:\n",
    "\n",
    "$$\\pi_{1:K}(\\mathbf{t}^{1:K};\\mathbf{t}_0^{1:K}) = \\tau_{1:K}(\\mathbf{t}^{1:K};\\mathbf{t}_0^{1:K}) - \\sum_{k=1}^{K-1}\\sum_{\\mathcal{K}_k \\in \\mathcal{K}_K} \\pi_{\\mathcal{K}_k}(\\mathbf{t}^{\\mathcal{K}_k};\\mathbf{t}_0^{\\mathcal{K}_k})$$\n",
    "\n",
    "where $\\tau = $ average combination effect (ACE) \n",
    "\n",
    "$$\\tau_{1:K}(\\mathbf{t}^{1:K};\\mathbf{t}_0^{1:K}) = \\mathbb{E}\\biggl[\\int \\Bigl\\{Y_i(\\mathbf{T}_i^{1:K} = \\mathbf{t}^{1:K}, \\mathbf{T}_i^{(K+1):J}) - Y_i(\\mathbf{T}_i^{1:K} = \\mathbf{t}_0^{1:K}, \\mathbf{T}_i^{(K+1):J})\\Bigr\\} dF(\\mathbf{T}_i^{(K+1):J}\\biggr]$$\n",
    "\n",
    "where $J$ is the total number of treatments and $K$ is the number of treatments of interest. Note that without loss of generality, we assume the first $K \\leq J$ treatments as those of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "J = k   # number of treatments\n",
    "K = 2   # number of treatments of interest\n",
    "assert(K <= J & K >= 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute average combination effect (ACE)\n",
    "def average_combination_effect(y, t, K_indices):\n",
    "    combo_idx = np.where(np.all(t[:, K_indices] == 1, axis=1))[0]\n",
    "    control_idx = np.where(np.all(t[:, K_indices] == 0, axis=1))[0]\n",
    "    ACE = np.mean(y[combo_idx]) - np.mean(y[control_idx])\n",
    "    return ACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to compute average marginal effect (AME). Only for base case when K=2.\n",
    "def average_marginal_effect(t_a, t_b):\n",
    "    a1_b1_idx = np.where((t[:, t_a] == 1) & (t[:, t_b] == 1))[0]\n",
    "    a1_b0_idx = np.where((t[:, t_a] == 1) & (t[:, t_b] == 0))[0]\n",
    "    a0_b1_idx = np.where((t[:, t_a] == 0) & (t[:, t_b] == 1))[0]\n",
    "    a0_b0_idx = np.where((t[:, t_a] == 0) & (t[:, t_b] == 0))[0]\n",
    "    AME = np.mean(y[a1_b1_idx]) - np.mean(y[a0_b1_idx]) + np.mean(y[a1_b0_idx]) - np.mean(y[a0_b0_idx])\n",
    "    return AME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recursive function for computing average marginal interaction effect (AMIE)\n",
    "def average_marginal_interaction_effect(y, t, K_indices):\n",
    "    # Base case\n",
    "    if len(K_indices) == 2:\n",
    "        return average_combination_effect(y, t, K_indices) - average_marginal_effect(K_indices[0], K_indices[1])\n",
    "    \n",
    "    # Recursive case\n",
    "    AMIE = average_combination_effect(y, t, K_indices)\n",
    "    for k in range(2, len(K_indices)):\n",
    "        subsets = list(combinations(K_indices, k))\n",
    "        for subset in subsets:\n",
    "            AMIE -= average_marginal_interaction_effect(y, t, subset)\n",
    "    return AMIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1064595750620718"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_marginal_interaction_effect(y, t, [0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "treatment combos      true betas    predicted betas       AMIE\n",
      "------------------  ------------  -----------------  ---------\n",
      "()                      0                0.00854169   0\n",
      "(0,)                   -1.03998         -1.04548     -1.98994\n",
      "(1,)                    0               -0.00407739  -0.7829\n",
      "(2,)                    0                0.00466065   0.083422\n",
      "(0, 1)                 -1.95104         -1.93547      1.10646\n",
      "(0, 2)                  0               -0.00817732   2.09497\n",
      "(1, 2)                  0.12784          0.117534     0.843058\n",
      "(0, 1, 2)              -0.316243        -0.312447    -7.22794\n"
     ]
    }
   ],
   "source": [
    "# Table that enumerates the treatment combinations (t), the true beta for each combination (fm.beta), the predicted\n",
    "# beta for each combination (results), and the AMIE for each combination.\n",
    "t_combos = []\n",
    "for i in range(k+1):\n",
    "    t_combos += list(combinations(range(k), i))\n",
    "\n",
    "table = []\n",
    "for i in range(len(t_combos)):\n",
    "    beta = fm.beta[i]\n",
    "    pred = results.params[i]\n",
    "    amie_combos = np.array([average_marginal_interaction_effect(y, t, t_combos[i])])\n",
    "    table.append([t_combos[i], beta, pred, amie_combos])\n",
    "print(tabulate(table, headers=[\"treatment combos\", \"true betas\", \"predicted betas\", \"AMIE\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "causal-factorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
